{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recomemder Systems in a Large-Scale Document-Based Data Extraction Application\n",
    "\n",
    "*Mauricio Alarcon <rmalarc@msn.com>*\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This project explores the role and implementation of recomemder systems in a document processing application. In this case, we will consider an information extraction applicaiton, whose function is to support automatic data extraction from large document collections such as legal contracts and other types of commercial agreements.\n",
    "\n",
    "## Application Workflow\n",
    "\n",
    "At a high level, the flow of the application is:\n",
    "\n",
    "1. Document is uploaded \n",
    "2. Perform OCR as needed\n",
    "3. **Detect document type\\***\n",
    "4. **Parse and Extract defined data elements\\***\n",
    "5. Return document with extracted datapoints for review\n",
    "\n",
    "* These \n",
    "\n",
    "## Recommender Systems in the Application Pipeline\n",
    "\n",
    "Let's explore the following areas where recommender systems can support the application:\n",
    "\n",
    "### Document Classification\n",
    "\n",
    "The goal with this collaborative filtering recomender is to produce a document classification once a user uploads a document. Let's keep in mind that detecting the document type is a pre-requisite to firing up subsequent data extraction tasks. We don't want to attempt to extract a birth date from a lease agreement, however we want to extract the data element whenever the application finds a birth certificate.\n",
    "\n",
    "Traditional document classification systems are based on machine learning algorithms such as logistic regression, naive bayes classification, amongst others. These supervised algorithms require an extensive dataset before they can start doing their job.\n",
    "\n",
    "What if you have an interactive application where you need to generate a doucument classification based upon limited user interaction and there is no prior training dataset? \n",
    "\n",
    "We could use one of the traditional classification algorithms in a way that we first generate a training datased by capturing several records of user interaction and then generate predictions. This system adds latency, as the system would not be able to generate predictions until a rich training dataset is first generated. This latency often makes these algorithms hard and impractical to implement due to the dependency on the existence of a rich training dataset.\n",
    "\n",
    "A general implementation of such an algorithm is presented here: https://github.com/rmalarc/DATA643/blob/master/src/main/scala/week4/project4-code.ipynb. The above mentioned project implements a low-latency document-document recommender system by generating a prospective lean training dataset captured from user interaction that minimizes prediction latency.\n",
    "\n",
    "### Data Element Definition Propagation\n",
    "\n",
    "As previously discussed, document detection directs the applicaiton flow towards certain data extraction subroutines. However, these sub-routines can be applicable to other document types. For instance, you may dates of birth mentioned not just in birth certificates but also in a variety of other documents. \n",
    "\n",
    "The goal here is to help the application propagate these data-extraction tasks to other documents in a context-aware collaborative filtering fashion.\n",
    "\n",
    "\n",
    "\n",
    "## Application Demonstration\n",
    "\n",
    "Let's see the implementation of the Document Classification Collaborative filtering. \n",
    "\n",
    "1. Document Upload\n",
    "![Document Upload](https://raw.githubusercontent.com/rmalarc/DATA643/master/src/main/scala/finalproject/1.png)\n",
    "\n",
    "2. Document Appears as Unknown\n",
    "![Unknown Doc](https://raw.githubusercontent.com/rmalarc/DATA643/master/src/main/scala/finalproject/2.png)\n",
    "\n",
    "3. User Assigns Document Type\n",
    "![New Doc Type](https://raw.githubusercontent.com/rmalarc/DATA643/master/src/main/scala/finalproject/3.png)\n",
    "\n",
    "4. New Document is Uploaded\n",
    "![New Document Upload](https://raw.githubusercontent.com/rmalarc/DATA643/master/src/main/scala/finalproject/4.png)\n",
    "\n",
    "5. Document is Recognized as Having the Same Type\n",
    "![New Document Recognized](https://raw.githubusercontent.com/rmalarc/DATA643/master/src/main/scala/finalproject/5.png)\n",
    "\n",
    "\n",
    "# Conclusions\n",
    "\n",
    "* Collaboarative Filtering techniques appear to be valuable for interactive applications where low-latency is desired and little to no training data is available\n",
    "* Machine-learning Applicaiton objectives have been with collaborative filtering recomendation systems\n",
    "* Additional value remains to be gained by enabling information-extraction subroutine propagation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.11",
   "language": "scala211",
   "name": "scala211"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala211",
   "pygments_lexer": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
