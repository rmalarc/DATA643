{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2\n",
    "\n",
    "The goal of this assignment is for you to try out different ways of implementing and configuring a recommender, and to evaluate your different approaches.\n",
    "\n",
    "For project 2, you’re asked to take some recommendation data (such as your toy movie dataset, Movielens, or another Dataset of your choosing), and implement at least two different recommendation algorithms on the data.  For example, content-based, user-user CF, and/or item-item CF.  You should evaluate different approaches, using different algorithms, normalization techniques, similarity methods, neighborhood sizes, etc.  You don’t need to be exhaustive—these are just some suggested possibilities.  You may use whatever third party libraries you want.  Please provide at least one graph, and a textual summary of your evaluation.\n",
    "\n",
    "You may work in a small group.  Please submit a link to your GitHub repository for your Jupyter notebook or RMarkdown file.  Due end of day on Sunday June 26th.\n",
    "\n",
    "**Requires the Jupyter-Scala language Kernel, available from: https://github.com/alexarchambault/jupyter-scala**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158 new artifact(s)\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "158 new artifacts in macro\n",
      "158 new artifacts in runtime\n",
      "158 new artifacts in compile\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classpath.add( \"org.apache.spark\" %% \"spark-core\" % \"1.6.1\",\n",
    "             \"org.apache.spark\" %% \"spark-mllib\" % \"1.6.1\",\n",
    "              \"org.apache.spark\" %% \"spark-sql\" % \"1.6.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Response\n",
    "\n",
    "## The Recommender System\n",
    "\n",
    "This week I'll try loading a more complicated dataset: Plain text. For the purpose of this exercise, I'll generate a Recipe-Recipe similarity model that generates recommendations based on the ingredients of the recipes. \n",
    "\n",
    "I'll focus on Appetizer Recipes from http://mc6help.tripod.com/RecipeLibrary/RecipeLibrary.htm\n",
    "\n",
    "## The Code\n",
    "\n",
    "### Firing up a Spark Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[36morg.apache.spark.{SparkConf, SparkContext}\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.apache.spark.sql._\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.apache.spark.sql.types._\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.apache.spark.mllib.linalg.Vectors\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.apache.spark.mllib.linalg.distributed.{MatrixEntry, RowMatrix}\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import org.apache.spark.{SparkConf, SparkContext}\n",
    "import org.apache.spark.sql._\n",
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.mllib.linalg.Vectors\n",
    "import org.apache.spark.mllib.linalg.distributed.{MatrixEntry, RowMatrix}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "16/06/25 23:37:42 INFO SparkContext: Running Spark version 1.6.1\n",
      "16/06/25 23:37:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "16/06/25 23:37:43 INFO SecurityManager: Changing view acls to: malarconba001\n",
      "16/06/25 23:37:43 INFO SecurityManager: Changing modify acls to: malarconba001\n",
      "16/06/25 23:37:43 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(malarconba001); users with modify permissions: Set(malarconba001)\n",
      "16/06/25 23:37:44 INFO Utils: Successfully started service 'sparkDriver' on port 45083.\n",
      "16/06/25 23:37:44 INFO Slf4jLogger: Slf4jLogger started\n",
      "16/06/25 23:37:44 INFO Remoting: Starting remoting\n",
      "16/06/25 23:37:45 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.1.15:45096]\n",
      "16/06/25 23:37:45 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 45096.\n",
      "16/06/25 23:37:45 INFO SparkEnv: Registering MapOutputTracker\n",
      "16/06/25 23:37:45 INFO SparkEnv: Registering BlockManagerMaster\n",
      "16/06/25 23:37:45 INFO DiskBlockManager: Created local directory at C:\\Users\\malarconba001\\AppData\\Local\\Temp\\blockmgr-68071797-f4f3-4d62-9582-4377ede2010e\n",
      "16/06/25 23:37:45 INFO MemoryStore: MemoryStore started with capacity 1773.8 MB\n",
      "16/06/25 23:37:45 INFO SparkEnv: Registering OutputCommitCoordinator\n",
      "16/06/25 23:37:45 INFO Utils: Successfully started service 'SparkUI' on port 4040.\n",
      "16/06/25 23:37:45 INFO SparkUI: Started SparkUI at http://192.168.1.15:4040\n",
      "16/06/25 23:37:45 INFO Executor: Starting executor ID driver on host localhost\n",
      "16/06/25 23:37:45 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45104.\n",
      "16/06/25 23:37:45 INFO NettyBlockTransferService: Server created on 45104\n",
      "16/06/25 23:37:45 INFO BlockManagerMaster: Trying to register BlockManager\n",
      "16/06/25 23:37:45 INFO BlockManagerMasterEndpoint: Registering block manager localhost:45104 with 1773.8 MB RAM, BlockManagerId(driver, localhost, 45104)\n",
      "16/06/25 23:37:45 INFO BlockManagerMaster: Registered BlockManager\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mconf\u001b[0m: org.apache.spark.SparkConf = org.apache.spark.SparkConf@29058a95\n",
       "\u001b[36msc\u001b[0m: org.apache.spark.SparkContext = org.apache.spark.SparkContext@3950693d"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "    val conf = new SparkConf()\n",
    "      .setAppName(\"week1-EstimatePi\")\n",
    "      .setMaster(\"local\") \n",
    "\n",
    "    val sc = new SparkContext(conf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading and Transformations\n",
    "\n",
    "The objective here is to:\n",
    "\n",
    "* Load the http://mc6help.tripod.com/RecipeLibrary/AllAppetizerRecipes.txt file\n",
    "* Transform into Zero filled matrix\n",
    "* Transform into Long-format data structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mcsv\u001b[0m: org.apache.spark.rdd.RDD[(String, Boolean, Long)] = MapPartitionsRDD[5] at map at Main.scala:30\n",
       "\u001b[36mres3_1\u001b[0m: Array[(String, Boolean, Long)] = \u001b[33mArray\u001b[0m(\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"* Exported from MasterCook *\"\u001b[0m, \u001b[32mtrue\u001b[0m, \u001b[32m0L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"\"\u001b[0m, \u001b[32mfalse\u001b[0m, \u001b[32m1L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Barbecue Pecans\"\u001b[0m, \u001b[32mfalse\u001b[0m, \u001b[32m2L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"\"\u001b[0m, \u001b[32mfalse\u001b[0m, \u001b[32m3L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Recipe By     : Possum Kingdom Lake Cookbook\"\u001b[0m, \u001b[32mfalse\u001b[0m, \u001b[32m4L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Serving Size  : 25    Preparation Time : 0:00\"\u001b[0m, \u001b[32mfalse\u001b[0m, \u001b[32m5L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Categories    :\"\u001b[0m, \u001b[32mfalse\u001b[0m, \u001b[32m6L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Amount  Measure       Ingredient -- Preparation Method\"\u001b[0m, \u001b[32mfalse\u001b[0m, \u001b[32m7L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"--------  ------------  --------------------------------\"\u001b[0m, \u001b[32mfalse\u001b[0m, \u001b[32m8L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"2   tablespoons  butter\"\u001b[0m, \u001b[32mfalse\u001b[0m, \u001b[32m9L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"1/4           cup  Worcestershire sauce\"\u001b[0m, \u001b[32mfalse\u001b[0m, \u001b[32m10L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"1    tablespoon  catsup\"\u001b[0m, \u001b[32mfalse\u001b[0m, \u001b[32m11L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"6        dashes  Hot sauce\"\u001b[0m, \u001b[32mfalse\u001b[0m, \u001b[32m12L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"4          cups  Pecans -- halves\"\u001b[0m, \u001b[32mfalse\u001b[0m, \u001b[32m13L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"salt -- to taste\"\u001b[0m, \u001b[32mfalse\u001b[0m, \u001b[32m14L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"\"\u001b[0m, \u001b[32mfalse\u001b[0m, \u001b[32m15L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\n",
       "    \u001b[32m\"Melt butter in a large saucepan; add Worcestershire sauce, , catsup, and hot sauce.\"\u001b[0m,\n",
       "\u001b[33m...\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "val csv = \n",
    "    sc\n",
    "        .textFile(\"AllAppetizerRecipes.txt\")\n",
    "        .map(t => t.trim)\n",
    "        .map(t => (t,t==\"* Exported from MasterCook *\") ) // add boolean if we have a record delimiter\n",
    "        .zipWithIndex // add record id\n",
    "        .map(r=>(r._1._1,r._1._2,r._2)) // flatten the nested index\n",
    "csv.take(20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, sample, we can see that the text file gets imported a line at a time per record. However, the recipes file is formatted as follows:\n",
    "\n",
    "```\n",
    "* Exported from MasterCook *\n",
    "\n",
    "                     Barbecue Pecans\n",
    "\n",
    "Recipe By     : Possum Kingdom Lake Cookbook\n",
    "Serving Size  : 25    Preparation Time : 0:00\n",
    "Categories    : \n",
    "  Amount  Measure       Ingredient -- Preparation Method\n",
    "--------  ------------  --------------------------------\n",
    "       2   tablespoons  butter\n",
    "     1/4           cup  Worcestershire sauce\n",
    "       1    tablespoon  catsup\n",
    "       6        dashes  Hot sauce\n",
    "       4          cups  Pecans -- halves\n",
    "                        salt -- to taste\n",
    "\n",
    "Melt butter in a large saucepan; add Worcestershire sauce, , catsup, and hot sauce.  \n",
    "\n",
    "Stir in nuts; spoon into a glass baking dish, spreading evenly.  toast at 400 degrees about 20 minutes, stirring frequently.  \n",
    "\n",
    "Turn out on absorbent towels, and sprinkle with salt.\n",
    "\n",
    "                                    - - - - - - - - - - - - - - - - - - - \n",
    "```\n",
    "\n",
    "The goal here is to map the file into: RecipeIngredients(RecipeName, Ingredient, IsUsed) \n",
    "\n",
    "Where:\n",
    "\n",
    "* Record Break: is the line: ```* Exported from MasterCook *```\n",
    "* An entire record is composed of the lines between record breaks\n",
    "* RecipeName: The third line in the record\n",
    "* Ingredient: The third column in the Ingredients table\n",
    "* IsUsed: Defaults to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mrecordIndexes\u001b[0m: org.apache.spark.rdd.RDD[(Long, Long)] = UnionRDD[12] at $plus$plus at Main.scala:27\n",
       "\u001b[36mrecordIndexesOffset\u001b[0m: org.apache.spark.rdd.RDD[(Long, Long)] = MapPartitionsRDD[13] at map at Main.scala:30\n",
       "\u001b[36mrecipeIndexTable\u001b[0m: org.apache.spark.rdd.RDD[(Long, Long)] = MapPartitionsRDD[17] at flatMap at Main.scala:33\n",
       "\u001b[36mres4_3\u001b[0m: Array[(Long, Long)] = \u001b[33mArray\u001b[0m(\n",
       "  \u001b[33m\u001b[0m(\u001b[32m0L\u001b[0m, \u001b[32m0L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m1L\u001b[0m, \u001b[32m0L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m2L\u001b[0m, \u001b[32m0L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m3L\u001b[0m, \u001b[32m0L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m4L\u001b[0m, \u001b[32m0L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m5L\u001b[0m, \u001b[32m0L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m6L\u001b[0m, \u001b[32m0L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m7L\u001b[0m, \u001b[32m0L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m8L\u001b[0m, \u001b[32m0L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m9L\u001b[0m, \u001b[32m0L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m10L\u001b[0m, \u001b[32m0L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m11L\u001b[0m, \u001b[32m0L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m12L\u001b[0m, \u001b[32m0L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m13L\u001b[0m, \u001b[32m0L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m14L\u001b[0m, \u001b[32m0L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m15L\u001b[0m, \u001b[32m0L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m16L\u001b[0m, \u001b[32m0L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m17L\u001b[0m, \u001b[32m0L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m18L\u001b[0m, \u001b[32m0L\u001b[0m),\n",
       "\u001b[33m...\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// The goal with this section is to end up with a recipeIndexTable collection that looks like: recipeIndexTable(RecordId,RecipeID)\n",
    "\n",
    "// Generate a recordIndex table (RecipeId, LineId) by relying in the presence and offset of the record break\n",
    "val recordIndexes =  csv.filter(_._2).map(_._3).zipWithIndex.map(r=>(r._2,r._1)) ++ sc.parallelize(Seq((csv.filter(_._2).count,csv.count)))\n",
    "\n",
    "// Now, let's just create an offset recordIndexes Table \n",
    "val recordIndexesOffset = recordIndexes.map(r=>(r._1-1,r._2-1))\n",
    "\n",
    "// and join it with the record indexes so we have the recipeIndexTable(RecordId,RecipeID)\n",
    "val recipeIndexTable = recordIndexes.join(recordIndexesOffset).flatMap(r=> (r._2._1 to r._2._2).map(t=>(t,r._1)))\n",
    "recipeIndexTable.collect.sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now join it to the imported data so we add the recipeID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mcsvIndexed\u001b[0m: org.apache.spark.rdd.RDD[(Long, ((String, Boolean), Long))] = MapPartitionsRDD[21] at join at Main.scala:27\n",
       "\u001b[36mres5_1\u001b[0m: Array[(Long, ((String, Boolean), Long))] = \u001b[33mArray\u001b[0m(\n",
       "  \u001b[33m\u001b[0m(\n",
       "    \u001b[32m3558L\u001b[0m,\n",
       "    \u001b[33m\u001b[0m(\n",
       "      \u001b[33m\u001b[0m(\n",
       "        \u001b[32m\"Blend well the cream cheese with the Brie cheese. Add the hazelnuts and apple; blend. Spread on melba toast or crackers.\"\u001b[0m,\n",
       "        \u001b[32mfalse\u001b[0m\n",
       "      ),\n",
       "      \u001b[32m92L\u001b[0m\n",
       "    )\n",
       "  ),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m1084L\u001b[0m, \u001b[33m\u001b[0m(\u001b[33m\u001b[0m(\u001b[32m\"- - - - - - - - - - - - - - - - - - -\"\u001b[0m, \u001b[32mfalse\u001b[0m), \u001b[32m28L\u001b[0m)),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m3586L\u001b[0m, \u001b[33m\u001b[0m(\u001b[33m\u001b[0m(\u001b[32m\"2            tb  Olive oil\"\u001b[0m, \u001b[32mfalse\u001b[0m), \u001b[32m93L\u001b[0m)),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m1410L\u001b[0m, \u001b[33m\u001b[0m(\u001b[33m\u001b[0m(\u001b[32m\"\"\u001b[0m, \u001b[32mfalse\u001b[0m), \u001b[32m37L\u001b[0m))\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "val csvIndexed = csv.map(r=>(r._3,(r._1,r._2))).join(recipeIndexTable)\n",
    "csvIndexed.take(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now combine the recipe lines separated by a pipe (|) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mrecipesText\u001b[0m: org.apache.spark.rdd.RDD[(Long, String)] = MapPartitionsRDD[31] at map at Main.scala:30\n",
       "\u001b[36mres6_1\u001b[0m: Array[(Long, String)] = \u001b[33mArray\u001b[0m(\n",
       "  \u001b[33m\u001b[0m(\n",
       "    \u001b[32m34L\u001b[0m,\n",
       "    \u001b[32m\"* Exported from MasterCook *||Cheese-Olive Balls||Recipe By     :|Serving Size  : 1     Preparation Time : 0:00|Categories    :|Amount  Measure       Ingredient -- Preparation Method|--------  ------------  --------------------------------|1/4      teaspoon  hot pepper sauce|1      teaspoon  paprika|1/2      teaspoon  salt|2          cups  sharp cheddar cheese -- grated|1/2           cup  butter|1           cup  flour -- sifted|olives||Mix ingredientsexcept olives  like a pie crust.  Wrap each olive with mixture.  spread the little balls on a pan and freeze.  Bake at 425 degrees for 12 minutes. Can be keep frozen in a bag. Serve hot.||||||||||- - - - - - - - - - - - - - - - - - -|||||Nutr. Assoc. : 0\"\u001b[0m\n",
       "  ),\n",
       "  \u001b[33m\u001b[0m(\n",
       "    \u001b[32m52L\u001b[0m,\n",
       "    \u001b[32m\"* Exported from MasterCook *||Stuffed Ripe Olives||Recipe By     : The Army Time Magazine/Nov. 13, 1978|Serving Size  : 1     Preparation Time : 0:00|Categories    :|Amount  Measure       Ingredient -- Preparation Method|--------  ------------  --------------------------------|6        ounces  jumbo ripe olives -- canned, pitted|1/4           cup  Italian dressing|1         bunch  green onion\u001b[33m...\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val recipesText = csvIndexed\n",
    "    .map(r=>(r._2._2,r._1,r._2._1._1))// let's flatten the nested list so we have RecipeId, Recipe Line Id and Recipe Line\n",
    "    .sortBy(r=>(r._1,r._2)) // Properly sort it so we have all lines consecutively arranged as per the recipe line id\n",
    "    .map(r=>(r._1,r._3)) // retain only the recipeid and recipe lines\n",
    "    .groupBy(_._1) // and group it by the RecipeId\n",
    "    .map( \n",
    "        g => (\n",
    "                g._1,    // return the RecipeId\n",
    "                g._2.map(_._2.trim).mkString(\"|\")  // and concatenate the nested array of recipe lines with a pipe\n",
    "        )\n",
    "    )\n",
    "\n",
    "recipesText.take(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, let's extract our data in a long format: RecipeIngredients(RecipeName,RecipeNameHash, IngredientName,IngredientNameHash, IsUsed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[36mscala.util.matching.Regex\u001b[0m\n",
       "\u001b[36mrecipeIngredients\u001b[0m: org.apache.spark.rdd.RDD[(String, String, Double)] = MapPartitionsRDD[35] at distinct at Main.scala:47\n",
       "\u001b[36mres7_2\u001b[0m: Array[(String, String, Double)] = \u001b[33mArray\u001b[0m(\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Fresh Gazpacho\"\u001b[0m, \u001b[32m\"Green Pepper -- chopped\"\u001b[0m, \u001b[32m1.0\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\n",
       "    \u001b[32m\"Cucumber Rye Surprises, Pk\"\u001b[0m,\n",
       "    \u001b[32m\"\"\"\n",
       "cucumbers -- sliced 1/8\" thick\n",
       "    \"\"\"\u001b[0m,\n",
       "    \u001b[32m1.0\u001b[0m\n",
       "  ),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Cheese-Olive Balls\"\u001b[0m, \u001b[32m\"flour -- sifted\"\u001b[0m, \u001b[32m1.0\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Fruit Kabobs\"\u001b[0m, \u001b[32m\"grapes\"\u001b[0m, \u001b[32m1.0\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Bacon Rollups\"\u001b[0m, \u001b[32m\"bacon\"\u001b[0m, \u001b[32m1.0\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Cheese Straws\"\u001b[0m, \u001b[32m\"butter\"\u001b[0m, \u001b[32m1.0\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Rhode Island Clam Cakes\"\u001b[0m, \u001b[32m\"pepper\"\u001b[0m, \u001b[32m1.0\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Baked Whole Garlic with French Bread\"\u001b[0m, \u001b[32m\"black pepper\"\u001b[0m, \u001b[32m1.0\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Dip For Sausage Balls\"\u001b[0m, \u001b[32m\"worcestershire sauce\"\u001b[0m, \u001b[32m1.0\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Crunchy Chocolate-Coconut Balls\"\u001b[0m, \u001b[32m\"whole wheat flakes -- crisp\"\u001b[0m, \u001b[32m1.0\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\n",
       "    \u001b[32m\"Buffalo-Style Crab Claws\"\u001b[0m,\n",
       "    \u001b[32m\"Alaska snow crab or blue -- crab cocktail claws\"\u001b[0m,\n",
       "\u001b[33m...\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scala.util.matching.Regex\n",
    "var recipeIngredients = recipesText\n",
    "    .flatMap{\n",
    "        text=>\n",
    "            val recipeName = {        // get the recipe name from the first part of the recipe record\n",
    "                val pattern = new Regex(\"\"\"\\* Exported from MasterCook \\*\\|\\|([^\\|]+)\\|\\|\"\"\", \"RecipeName\") \n",
    "                pattern.findFirstMatchIn(text._2).get.group(\"RecipeName\")  \n",
    "            }\n",
    "\n",
    "            \"\"\"(?s)----\\|.*?\\|\\|\"\"\".r   /* Let's find the recipe table, which is all the stuff \n",
    "                                                 between the header and 2 consecutive pipes (new lines) */\n",
    "                .findFirstMatchIn(text._2)    // get the first match\n",
    "                .map(r=>r.matched)            // and return the matched text from the regex object\n",
    "                .getOrElse(\"\")                // get or default to whitespace\n",
    "                .split(\"\\\\|\")                 // and now process the table lines\n",
    "                .map(\n",
    "                    _.trim.replaceAll(\" {2,}\",\"\\\\|\")  // for each line, let's pipe delimit the columns.\n",
    "                )\n",
    "                .filter(r=>(!r.isEmpty)&&(r!=\"----\")&&(r.length>2)) // filtering out the empty ones and short aberrations\n",
    "                .map { r=>   // for each recipe line\n",
    "                    val v = r.split(\"\\\\|\")    // split it into an iterator by the pipe sign\n",
    "                    (recipeName, v(v.length-1),1.00) // amd return (RecipeName, IngredientName, IsUSed)\n",
    "                }\n",
    "    }.distinct\n",
    "\n",
    "recipeIngredients.collect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets have a freestanding list of recipes and ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mingredients\u001b[0m: org.apache.spark.rdd.RDD[(String, Long)] = ZippedWithIndexRDD[40] at zipWithIndex at Main.scala:25\n",
       "\u001b[36mres8_1\u001b[0m: Array[(String, Long)] = \u001b[33mArray\u001b[0m(\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"bread\"\u001b[0m, \u001b[32m0L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"French bread loaf -- sliced and heated\"\u001b[0m, \u001b[32m1L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"cucumber -- thinly sliced\"\u001b[0m, \u001b[32m2L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"pine nuts -- toasted\"\u001b[0m, \u001b[32m3L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"soy sauce\"\u001b[0m, \u001b[32m4L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"-- crumbled\"\u001b[0m, \u001b[32m5L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"sour cream -- or yogurt\"\u001b[0m, \u001b[32m6L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Salt -- pepper\"\u001b[0m, \u001b[32m7L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Hot sauce\"\u001b[0m, \u001b[32m8L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"salt, to taste\"\u001b[0m, \u001b[32m9L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"chicken pieces -- see notes\"\u001b[0m, \u001b[32m10L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"hot chili oil\"\u001b[0m, \u001b[32m11L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"lettuce leaves\"\u001b[0m, \u001b[32m12L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Mushrooms -- coarsely chopped\"\u001b[0m, \u001b[32m13L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"catsup\"\u001b[0m, \u001b[32m14L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"chopped pecans -- or walnuts\"\u001b[0m, \u001b[32m15L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"bean sprouts\"\u001b[0m, \u001b[32m16L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"minced parsley\"\u001b[0m, \u001b[32m17L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"segmented\"\u001b[0m, \u001b[32m18L\u001b[0m),\n",
       "\u001b[33m...\u001b[0m\n",
       "\u001b[36mrecipes\u001b[0m: org.apache.spark.rdd.RDD[(String, Long)] = ZippedWithIndexRDD[45] at zipWithIndex at Main.scala:31\n",
       "\u001b[36mres8_3\u001b[0m: Array[(String, Long)] = \u001b[33mArray\u001b[0m(\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Crunchy Chocolate-Coconut Balls\"\u001b[0m, \u001b[32m0L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Shirlie's Cheese Ball\"\u001b[0m, \u001b[32m1L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Corn 'n Bacon Sticks, Pk\"\u001b[0m, \u001b[32m2L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Rice Krispies Balls, Pk\"\u001b[0m, \u001b[32m3L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Champagne Batter\"\u001b[0m, \u001b[32m4L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Toasted ID Bits, Pk\"\u001b[0m, \u001b[32m5L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Crab And Avocado Cocktail\"\u001b[0m, \u001b[32m6L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Deviled Egg Slices, Pk\"\u001b[0m, \u001b[32m7L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Spinach Balls\"\u001b[0m, \u001b[32m8L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Bacon Rollups\"\u001b[0m, \u001b[32m9L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Italian Roasted Vegetables\"\u001b[0m, \u001b[32m10L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Curried Pecans\"\u001b[0m, \u001b[32m11L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Stuffed Mushrooms\"\u001b[0m, \u001b[32m12L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Wild Mushroom Torta\"\u001b[0m, \u001b[32m13L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Ants on a Log\"\u001b[0m, \u001b[32m14L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Cheese Ball\"\u001b[0m, \u001b[32m15L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Spinach, Mushroom, and Mozzarella Wrap\"\u001b[0m, \u001b[32m16L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Bruschetta with Portobellos\"\u001b[0m, \u001b[32m17L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Sweet-Sour Meatballs, Pk\"\u001b[0m, \u001b[32m18L\u001b[0m),\n",
       "\u001b[33m...\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val ingredients = recipeIngredients.map(_._2).distinct.zipWithIndex\n",
    "ingredients.collect\n",
    "val recipes = recipeIngredients.map(_._1).distinct.zipWithIndex\n",
    "recipes.collect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's finally bake the indexes along with the recipeIngredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mwithIngredientsIndexed\u001b[0m: org.apache.spark.rdd.RDD[(String, (Iterable[(String, String, Double)], Long))] = MapPartitionsRDD[50] at join at Main.scala:27\n",
       "\u001b[36mres9_1\u001b[0m: Array[(String, (Iterable[(String, String, Double)], Long))] = \u001b[33mArray\u001b[0m(\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"bread\"\u001b[0m, \u001b[33m\u001b[0m(\u001b[33mCompactBuffer\u001b[0m(\u001b[33m\u001b[0m(\u001b[32m\"Chicken Almond Dainties\"\u001b[0m, \u001b[32m\"bread\"\u001b[0m, \u001b[32m1.0\u001b[0m)), \u001b[32m0L\u001b[0m)),\n",
       "  \u001b[33m\u001b[0m(\n",
       "    \u001b[32m\"French bread loaf -- sliced and heated\"\u001b[0m,\n",
       "    \u001b[33m\u001b[0m(\n",
       "      \u001b[33mCompactBuffer\u001b[0m(\n",
       "        \u001b[33m\u001b[0m(\n",
       "          \u001b[32m\"Baked Whole Garlic with French Bread\"\u001b[0m,\n",
       "          \u001b[32m\"French bread loaf -- sliced and heated\"\u001b[0m,\n",
       "          \u001b[32m1.0\u001b[0m\n",
       "        )\n",
       "      ),\n",
       "      \u001b[32m1L\u001b[0m\n",
       "    )\n",
       "  ),\n",
       "  \u001b[33m\u001b[0m(\n",
       "    \u001b[32m\"cucumber -- thinly sliced\"\u001b[0m,\n",
       "    \u001b[33m\u001b[0m(\u001b[33mCompactBuffer\u001b[0m(\u001b[33m\u001b[0m(\u001b[32m\"Snack Sandwiches\"\u001b[0m, \u001b[32m\"cucumber -- thinly sliced\"\u001b[0m, \u001b[32m1.0\u001b[0m)), \u001b[32m2L\u001b[0m)\n",
       "  ),\n",
       "  \u001b[33m\u001b[0m(\n",
       "\u001b[33m...\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val withIngredientsIndexed = recipeIngredients.groupBy(_._2).join(ingredients)\n",
    "withIngredientsIndexed.take(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time to flatten the group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mwithIngredientsIndexedFlat\u001b[0m: org.apache.spark.rdd.RDD[(String, String, Long, Double)] = MapPartitionsRDD[51] at flatMap at Main.scala:25\n",
       "\u001b[36mres10_1\u001b[0m: Array[(String, String, Long, Double)] = \u001b[33mArray\u001b[0m(\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Chicken Almond Dainties\"\u001b[0m, \u001b[32m\"bread\"\u001b[0m, \u001b[32m0L\u001b[0m, \u001b[32m1.0\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\n",
       "    \u001b[32m\"Baked Whole Garlic with French Bread\"\u001b[0m,\n",
       "    \u001b[32m\"French bread loaf -- sliced and heated\"\u001b[0m,\n",
       "    \u001b[32m1L\u001b[0m,\n",
       "    \u001b[32m1.0\u001b[0m\n",
       "  ),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Snack Sandwiches\"\u001b[0m, \u001b[32m\"cucumber -- thinly sliced\"\u001b[0m, \u001b[32m2L\u001b[0m, \u001b[32m1.0\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\n",
       "    \u001b[32m\"Mushrooms Filled with Feta Cheese and Pine Nuts\"\u001b[0m,\n",
       "    \u001b[32m\"pine nuts -- toasted\"\u001b[0m,\n",
       "    \u001b[32m3L\u001b[0m,\n",
       "    \u001b[32m1.0\u001b[0m\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val withIngredientsIndexedFlat = withIngredientsIndexed.flatMap(r => r._2._1.map(x => (x._1,x._2,r._2._2,x._3)))\n",
    "withIngredientsIndexedFlat.take(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And add the recipe ID following the same methodology:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mrecipeIngredientsIndexed\u001b[0m: org.apache.spark.rdd.RDD[(String, Long, String, Long, Double)] = MapPartitionsRDD[57] at flatMap at Main.scala:30\n",
       "\u001b[36mres11_1\u001b[0m: Array[(String, Long, String, Long, Double)] = \u001b[33mArray\u001b[0m(\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Crunchy Chocolate-Coconut Balls\"\u001b[0m, \u001b[32m0L\u001b[0m, \u001b[32m\"egg -- slightly beaten\"\u001b[0m, \u001b[32m148L\u001b[0m, \u001b[32m1.0\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Crunchy Chocolate-Coconut Balls\"\u001b[0m, \u001b[32m0L\u001b[0m, \u001b[32m\"sweet chocolate squares\"\u001b[0m, \u001b[32m169L\u001b[0m, \u001b[32m1.0\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Crunchy Chocolate-Coconut Balls\"\u001b[0m, \u001b[32m0L\u001b[0m, \u001b[32m\"butter\"\u001b[0m, \u001b[32m285L\u001b[0m, \u001b[32m1.0\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Crunchy Chocolate-Coconut Balls\"\u001b[0m, \u001b[32m0L\u001b[0m, \u001b[32m\"coconut flakes\"\u001b[0m, \u001b[32m322L\u001b[0m, \u001b[32m1.0\u001b[0m)\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val recipeIngredientsIndexed = withIngredientsIndexedFlat\n",
    "    .groupBy(_._1)\n",
    "    .join(recipes)\n",
    "    .flatMap(r => r._2._1.map(x => (x._1,r._2._2,x._2,x._3,x._4)))\n",
    "\n",
    "recipeIngredientsIndexed.take(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the RDD into a Sql Context\n",
    "\n",
    "Thinking that it may be useful, here it is:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36msqlContext\u001b[0m: org.apache.spark.sql.SQLContext = org.apache.spark.sql.SQLContext@7770f984"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// lot's of code from : http://spark.apache.org/docs/latest/sql-programming-guide.html\n",
    "\n",
    "// sc is an existing SparkContext.\n",
    "val sqlContext = new org.apache.spark.sql.SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[36morg.apache.spark.sql.Row\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.apache.spark.sql.types.{StructType,StructField,StringType,DoubleType}\u001b[0m\n",
       "\u001b[36mschema\u001b[0m: org.apache.spark.sql.types.StructType = \u001b[33mStructType\u001b[0m(\n",
       "  StructField(recipeName,StringType,true),\n",
       "  StructField(ingredientName,StringType,true),\n",
       "  StructField(isUsed,DoubleType,true)\n",
       ")\n",
       "\u001b[36mrowRDD\u001b[0m: org.apache.spark.rdd.RDD[org.apache.spark.sql.Row] = MapPartitionsRDD[58] at map at Main.scala:41\n",
       "\u001b[36mrecipeIngredientsDataFrame\u001b[0m: org.apache.spark.sql.DataFrame = [recipeName: string, ingredientName: string, isUsed: double]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// Import Row.\n",
    "import org.apache.spark.sql.Row;\n",
    "\n",
    "// Import Spark SQL data types\n",
    "import org.apache.spark.sql.types.{StructType,StructField,StringType,DoubleType};\n",
    "// Generate the schema based on the string of schema\n",
    "val schema =\n",
    "  StructType(List(StructField(\"recipeName\", StringType, true)\n",
    "             ,StructField(\"ingredientName\", StringType, true)\n",
    "             ,StructField(\"isUsed\", DoubleType, true)\n",
    "            )\n",
    "            )\n",
    "\n",
    "// Convert records of the RDD (people) to Rows.\n",
    "val rowRDD = recipeIngredients.map(p => Row(p._1, p._2,p._3))\n",
    "\n",
    "// Apply the schema to the RDD.\n",
    "val recipeIngredientsDataFrame = sqlContext.createDataFrame(rowRDD, schema)\n",
    "\n",
    "// Register the DataFrames as a table.\n",
    "recipeIngredientsDataFrame.registerTempTable(\"recipeingredients\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's query the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mres14\u001b[0m: Array[org.apache.spark.sql.Row] = \u001b[33mArray\u001b[0m(\n",
       "  [Fruit Salsa Dip,cilantro,1.0],\n",
       "  [Tuna Appetizers,dried cilantro,1.0],\n",
       "  [Southwestern Chicken Filo Triangles,fresh cilantro -- minced,1.0],\n",
       "  [Southwestern Chicken Filo Triangles,fresh cilantro -- finely minced,1.0],\n",
       "  [Pot Stickers,Cilantro -- minced,1.0],\n",
       "  [Crab And Avocado Cocktail,cilantro; fresh -- snipped,1.0],\n",
       "  [Vietnamese Spring Rolls,cilantro -- minced,1.0]\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sqlContext.sql(\"SELECT * FROM recipeingredients where upper(ingredientName) like '%CILANTRO%'\").collect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I thought I would use the SQL collection to pivot the matix. However, the performance is so poor when I ran it that I'm completely ommiting it from the excercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming into a Matrix and Generating the Cosine Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction \u001b[36mdisplayTable\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// Helper function that displays a nicely formatted table\n",
    "def displayTable(table:List[Map[String, String]])(implicit publish: jupyter.api.Publish[jupyter.api.Evidence]): Unit = {\n",
    "    val keys = table.flatMap(r=>r.keys).distinct.sorted\n",
    "    val header = \"<th>\"+keys.mkString(\"</th><th>\")+\"</th>\"\n",
    "    val rows = \"<tr>\"+table.map(r=>keys.map(k=>\"<td>\"+r.getOrElse(k,\"&nbsp;\")+\"</td>\")).mkString(\"</tr><tr>\")+\"</tr>\"\n",
    "    publish.display(\"table\",(\"text/html\" -> (\"<table>\"+header+rows+\"</table>\")))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mres16_0\u001b[0m: Int = \u001b[32m626\u001b[0m\n",
       "\u001b[36mres16_1\u001b[0m: Int = \u001b[32m103\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// I don't yet know why but I have to get these counts and hard code them into the functor. \n",
    "ingredients.count.toInt\n",
    "recipes.count.toInt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mrecipeIngredientsMatrix\u001b[0m: org.apache.spark.mllib.linalg.distributed.RowMatrix = org.apache.spark.mllib.linalg.distributed.RowMatrix@13b669c3\n",
       "\u001b[36mres17_1\u001b[0m: Array[org.apache.spark.mllib.linalg.Vector] = \u001b[33mArray\u001b[0m(\n",
       "  (628,[147,199,286,439,501],[1.0,1.0,1.0,1.0,1.0]),\n",
       "  (628,[99,124,135,228,285,382,472,487],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0]),\n",
       "  (628,[115,282,583],[1.0,1.0,1.0]),\n",
       "  (628,[10,99,165,184,200,302,397],[1.0,1.0,1.0,1.0,1.0,1.0,1.0]),\n",
       "  (628,[75,250,326,389,415,446,531,532,572],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\n",
       ")\n",
       "\u001b[36mcs\u001b[0m: org.apache.spark.mllib.linalg.distributed.CoordinateMatrix = org.apache.spark.mllib.linalg.distributed.CoordinateMatrix@10ece095\n",
       "\u001b[36mic\u001b[0m: Array[(String, Long)] = \u001b[33mArray\u001b[0m(\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"bread\"\u001b[0m, \u001b[32m0L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"French bread loaf -- sliced and heated\"\u001b[0m, \u001b[32m1L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"cucumber -- thinly sliced\"\u001b[0m, \u001b[32m2L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"pine nuts -- toasted\"\u001b[0m, \u001b[32m3L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"soy sauce\"\u001b[0m, \u001b[32m4L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"-- crumbled\"\u001b[0m, \u001b[32m5L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"sour cream -- or yogurt\"\u001b[0m, \u001b[32m6L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Salt -- pepper\"\u001b[0m, \u001b[32m7L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Hot sauce\"\u001b[0m, \u001b[32m8L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"salt, to taste\"\u001b[0m, \u001b[32m9L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"chicken pieces -- see notes\"\u001b[0m, \u001b[32m10L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"hot chili oil\"\u001b[0m, \u001b[32m11L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"lettuce leaves\"\u001b[0m, \u001b[32m12L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Mushrooms -- coarsely chopped\"\u001b[0m, \u001b[32m13L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"catsup\"\u001b[0m, \u001b[32m14L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"chopped pecans -- or walnuts\"\u001b[0m, \u001b[32m15L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"bean sprouts\"\u001b[0m, \u001b[32m16L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"minced parsley\"\u001b[0m, \u001b[32m17L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"segmented\"\u001b[0m, \u001b[32m18L\u001b[0m),\n",
       "\u001b[33m...\u001b[0m\n",
       "\u001b[36mres17_4\u001b[0m: Array[(Array[String], Array[String], Double)] = \u001b[33mArray\u001b[0m(\n",
       "  \u001b[33m\u001b[0m(\u001b[33mArray\u001b[0m(\u001b[32m\"coconut flakes\"\u001b[0m), \u001b[33mArray\u001b[0m(\u001b[32m\"confectioner's sugar\"\u001b[0m), \u001b[32m1.0000000000000002\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[33mArray\u001b[0m(\u001b[32m\"minced parsley\"\u001b[0m), \u001b[33mArray\u001b[0m(\u001b[32m\"blue cheese\"\u001b[0m), \u001b[32m1.0\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[33mArray\u001b[0m(\u001b[32m\"Red Onion -- minced\"\u001b[0m), \u001b[33mArray\u001b[0m(\u001b[32m\"Vegetable Juice\"\u001b[0m), \u001b[32m1.0\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[33mArray\u001b[0m(\u001b[32m\"ripe olives\"\u001b[0m), \u001b[33mArray\u001b[0m(\u001b[32m\"julienned fresh basil leaves\"\u001b[0m), \u001b[32m1.0\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[33mArray\u001b[0m(\u001b[32m\"Sesame Oil\"\u001b[0m), \u001b[33mArray\u001b[0m(\u001b[32m\"Water\"\u001b[0m), \u001b[32m1.0\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[33mArray\u001b[0m(\u001b[32m\"Low Sodium Soy Sauce\"\u001b[0m), \u001b[33mArray\u001b[0m(\u001b[32m\"Ginger Root -- grated fresh\"\u001b[0m), \u001b[32m1.0\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[33mArray\u001b[0m(\u001b[32m\"(such as kalamata or\"\u001b[0m), \u001b[33mArray\u001b[0m(\u001b[32m\"imported black olives\"\u001b[0m), \u001b[32m1.0\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[33mArray\u001b[0m(\u001b[32m\"Garlic cloves -- crushed\"\u001b[0m), \u001b[33mArray\u001b[0m(\u001b[32m\"Olive oil\"\u001b[0m), \u001b[32m1.0\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[33mArray\u001b[0m(\u001b[32m\"Corn oil or soy margarine\"\u001b[0m), \u001b[33mArray\u001b[0m(\u001b[32m\"Spinach -- fresh\"\u001b[0m), \u001b[32m1.0\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[33mArray\u001b[0m(\u001b[32m\"cooked rice\"\u001b[0m), \u001b[33mArray\u001b[0m(\u001b[32m\"Fresh basil -- chopped, for garnish\"\u001b[0m), \u001b[32m1.0\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[33mArray\u001b[0m(\u001b[32m\"Cilantro -- minced\"\u001b[0m), \u001b[33mArray\u001b[0m(\u001b[32m\"plus 1 tablespoon warm water\"\u001b[0m), \u001b[32m1.0\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[33mArray\u001b[0m(\u001b[32m\"dried onion flakes\"\u001b[0m), \u001b[33mArray\u001b[0m(\u001b[32m\"oregano leaves\"\u001b[0m), \u001b[32m1.0\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\n",
       "    \u001b[33mArray\u001b[0m(\u001b[32m\"red bell pepper -- seeded\"\u001b[0m),\n",
       "    \u001b[33mArray\u001b[0m(\u001b[32m\"roma tomato -- peeled, seeded and\"\u001b[0m),\n",
       "    \u001b[32m1.0\u001b[0m\n",
       "  ),\n",
       "  \u001b[33m\u001b[0m(\u001b[33mArray\u001b[0m(\u001b[32m\"cider vinegar\"\u001b[0m), \u001b[33mArray\u001b[0m(\u001b[32m\"hot chili sauce\"\u001b[0m), \u001b[32m1.0\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[33mArray\u001b[0m(\u001b[32m\"long grain rice -- uncooked\"\u001b[0m), \u001b[33mArray\u001b[0m(\u001b[32m\"lemon\"\u001b[0m), \u001b[32m1.0\u001b[0m),\n",
       "\u001b[33m...\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// it also sucks that the only silimarity function is buried in a RowMatrix object, which only takes dense vectors\n",
    "val recipeIngredientsMatrix = new RowMatrix(\n",
    "    recipeIngredientsIndexed\n",
    "        .groupBy(_._2)\n",
    "        .map(\n",
    "            r=>\n",
    "                Vectors.sparse(628,r._2.map(i=> (i._4.toInt,i._5)).toSeq)\n",
    "        )\n",
    ")\n",
    "\n",
    "recipeIngredientsMatrix.rows.take(5)\n",
    "\n",
    "val cs = recipeIngredientsMatrix.columnSimilarities\n",
    "\n",
    "val ic = ingredients.collect\n",
    "cs.entries\n",
    "  .map {\n",
    "    case MatrixEntry(i, j, u) => (i, j, u) }\n",
    "  .collect\n",
    "//  .map(r => (ic.filter(ri => ri._2 == r._1).map(_._1), ic.filter(ri => ri._2 == r._2).map(_._1), r._3.toDouble))\n",
    "  .map(r => (ic.filter(ri => ri._2 == r._1).map(_._1), ic.filter(ri => ri._2 == r._2).map(_._1), r._3.toDouble))\n",
    "  .sortBy(-_._3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mingredientsRecipeMatrix\u001b[0m: org.apache.spark.mllib.linalg.distributed.RowMatrix = org.apache.spark.mllib.linalg.distributed.RowMatrix@1554fd67\n",
       "\u001b[36mres18_1\u001b[0m: Array[org.apache.spark.mllib.linalg.Vector] = \u001b[33mArray\u001b[0m(\n",
       "  (103,[74],[1.0]),\n",
       "  (103,[3],[1.0]),\n",
       "  (103,[41],[1.0]),\n",
       "  (103,[69],[1.0]),\n",
       "  (103,[91],[1.0])\n",
       ")\n",
       "\u001b[36mcs\u001b[0m: org.apache.spark.mllib.linalg.distributed.CoordinateMatrix = org.apache.spark.mllib.linalg.distributed.CoordinateMatrix@5e6fe153\n",
       "\u001b[36mrecipeIngredientsLocal\u001b[0m: Array[(String, String, Double)] = \u001b[33mArray\u001b[0m(\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Fresh Gazpacho\"\u001b[0m, \u001b[32m\"Green Pepper -- chopped\"\u001b[0m, \u001b[32m1.0\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\n",
       "    \u001b[32m\"Cucumber Rye Surprises, Pk\"\u001b[0m,\n",
       "    \u001b[32m\"\"\"\n",
       "cucumbers -- sliced 1/8\" thick\n",
       "    \"\"\"\u001b[0m,\n",
       "    \u001b[32m1.0\u001b[0m\n",
       "  ),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Cheese-Olive Balls\"\u001b[0m, \u001b[32m\"flour -- sifted\"\u001b[0m, \u001b[32m1.0\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Fruit Kabobs\"\u001b[0m, \u001b[32m\"grapes\"\u001b[0m, \u001b[32m1.0\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Bacon Rollups\"\u001b[0m, \u001b[32m\"bacon\"\u001b[0m, \u001b[32m1.0\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Cheese Straws\"\u001b[0m, \u001b[32m\"butter\"\u001b[0m, \u001b[32m1.0\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Rhode Island Clam Cakes\"\u001b[0m, \u001b[32m\"pepper\"\u001b[0m, \u001b[32m1.0\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Baked Whole Garlic with French Bread\"\u001b[0m, \u001b[32m\"black pepper\"\u001b[0m, \u001b[32m1.0\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Dip For Sausage Balls\"\u001b[0m, \u001b[32m\"worcestershire sauce\"\u001b[0m, \u001b[32m1.0\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Crunchy Chocolate-Coconut Balls\"\u001b[0m, \u001b[32m\"whole wheat flakes -- crisp\"\u001b[0m, \u001b[32m1.0\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\n",
       "    \u001b[32m\"Buffalo-Style Crab Claws\"\u001b[0m,\n",
       "    \u001b[32m\"Alaska snow crab or blue -- crab cocktail claws\"\u001b[0m,\n",
       "\u001b[33m...\u001b[0m\n",
       "\u001b[36mrc\u001b[0m: Array[(String, Long)] = \u001b[33mArray\u001b[0m(\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Crunchy Chocolate-Coconut Balls\"\u001b[0m, \u001b[32m0L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Shirlie's Cheese Ball\"\u001b[0m, \u001b[32m1L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Corn 'n Bacon Sticks, Pk\"\u001b[0m, \u001b[32m2L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Rice Krispies Balls, Pk\"\u001b[0m, \u001b[32m3L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Champagne Batter\"\u001b[0m, \u001b[32m4L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Toasted ID Bits, Pk\"\u001b[0m, \u001b[32m5L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Crab And Avocado Cocktail\"\u001b[0m, \u001b[32m6L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Deviled Egg Slices, Pk\"\u001b[0m, \u001b[32m7L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Spinach Balls\"\u001b[0m, \u001b[32m8L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Bacon Rollups\"\u001b[0m, \u001b[32m9L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Italian Roasted Vegetables\"\u001b[0m, \u001b[32m10L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Curried Pecans\"\u001b[0m, \u001b[32m11L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Stuffed Mushrooms\"\u001b[0m, \u001b[32m12L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Wild Mushroom Torta\"\u001b[0m, \u001b[32m13L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Ants on a Log\"\u001b[0m, \u001b[32m14L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Cheese Ball\"\u001b[0m, \u001b[32m15L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Spinach, Mushroom, and Mozzarella Wrap\"\u001b[0m, \u001b[32m16L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Bruschetta with Portobellos\"\u001b[0m, \u001b[32m17L\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"Sweet-Sour Meatballs, Pk\"\u001b[0m, \u001b[32m18L\u001b[0m),\n",
       "\u001b[33m...\u001b[0m\n",
       "\u001b[36mcse\u001b[0m: Array[collection.immutable.Map[String,String]] = \u001b[33mArray\u001b[0m(\n",
       "  \u001b[33mMap\u001b[0m(\n",
       "    \u001b[32m\"Ingredients 1\"\u001b[0m -> \u001b[32m\"dried apricots<br>graham cracker crumbs<br>fresh cranberries -- rinsed and drained<br>red food coloring<br>confectioner's sugar<br>coconut flakes<br>pecans<br>grated orange peel -- from 1 orange<br>green food coloring<br>butter\"\u001b[0m,\n",
       "    \u001b[32m\"  Cosine Similarity\"\u001b[0m -> \u001b[32m\"0.47809144373375745\"\u001b[0m,\n",
       "    \u001b[32m\" Recipe 2\"\u001b[0m -> \u001b[32m\"Orange Coconut Balls\"\u001b[0m,\n",
       "    \u001b[32m\"Ingredients 2\"\u001b[0m -> \u001b[32m\"water<br>graham cracker crumbs<br>chopped pecans<br>confectioner's sugar<br>butter<br>coconut flakes<br>frozen orange juice concentrate -- thawed\"\u001b[0m,\n",
       "    \u001b[32m\" Recipe 1\"\u001b[0m -> \u001b[32m\"Cranberry Coconut Fruit Balls\"\u001b[0m\n",
       "  ),\n",
       "  \u001b[33mMap\u001b[0m(\n",
       "    \u001b[32m\"Ingredients 1\"\u001b[0m -> \u001b[32m\"whole wheat flakes -- crisp<br>sweet chocolate squares<br>confectioner's sugar<br>coconut flakes<br>egg -- slightly beaten<br>butter\"\u001b[0m,\n",
       "    \u001b[32m\"  Cosine Similarity\"\u001b[0m -> \u001b[32m\"0.4629100498862757\"\u001b[0m,\n",
       "    \u001b[32m\" Recipe 2\"\u001b[0m -> \u001b[32m\"Orange Coconut Balls\"\u001b[0m,\n",
       "    \u001b[32m\"Ingredients 2\"\u001b[0m -> \u001b[32m\"water<br>graham cracker crumbs<br>chopped pecans<br>confectioner's sugar<br>butter<br>coconut flakes<br>frozen orange juice concentrate \u001b[33m...\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val ingredientsRecipeMatrix = new RowMatrix(\n",
    "    recipeIngredientsIndexed\n",
    "        .groupBy(_._4)\n",
    "        .map(\n",
    "            r=>\n",
    "                Vectors.sparse(103,r._2.map(i=> (i._2.toInt,i._5)).toSeq)            \n",
    "        )\n",
    ")\n",
    "\n",
    "ingredientsRecipeMatrix.rows.take(5)\n",
    "\n",
    "val cs = ingredientsRecipeMatrix.columnSimilarities\n",
    "\n",
    "// let's collect the ingredients so we can see them\n",
    "val recipeIngredientsLocal = recipeIngredients.collect\n",
    "\n",
    "val rc = recipes.collect\n",
    "\n",
    "// format the recipe-recipe as an html table for display purposes\n",
    "val cse = cs.entries\n",
    "      .map {\n",
    "        case MatrixEntry(i, j, u) => (i, j, u) }\n",
    "      .collect\n",
    "      .map(r => (rc.filter(ri => ri._2 == r._1).map(_._1), rc.filter(ri => ri._2 == r._2).map(_._1), r._3.toDouble))\n",
    "      .sortBy(-_._3)\n",
    "      .map(r=> Map(\" Recipe 1\"->r._1.mkString\n",
    "                   ,\"Ingredients 1\"->recipeIngredientsLocal.filter(_._1==r._1.mkString).map(_._2).mkString(\"<br>\")\n",
    "                   ,\" Recipe 2\"->r._2.mkString\n",
    "                   ,\"Ingredients 2\"->recipeIngredientsLocal.filter(_._1==r._2.mkString).map(_._2).mkString(\"<br>\")\n",
    "                   ,\"  Cosine Similarity\"->r._3.toString))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Recipe-Recipe Simliarity Based Model\n",
    "\n",
    "Let's see the top-20 similar reciples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><th>  Cosine Similarity</th><th> Recipe 1</th><th> Recipe 2</th><th>Ingredients 1</th><th>Ingredients 2</th><tr>List(<td>0.47809144373375745</td>, <td>Cranberry Coconut Fruit Balls</td>, <td>Orange Coconut Balls</td>, <td>dried apricots<br>graham cracker crumbs<br>fresh cranberries -- rinsed and drained<br>red food coloring<br>confectioner's sugar<br>coconut flakes<br>pecans<br>grated orange peel -- from 1 orange<br>green food coloring<br>butter</td>, <td>water<br>graham cracker crumbs<br>chopped pecans<br>confectioner's sugar<br>butter<br>coconut flakes<br>frozen orange juice concentrate -- thawed</td>)</tr><tr>List(<td>0.4629100498862757</td>, <td>Crunchy Chocolate-Coconut Balls</td>, <td>Orange Coconut Balls</td>, <td>whole wheat flakes -- crisp<br>sweet chocolate squares<br>confectioner's sugar<br>coconut flakes<br>egg -- slightly beaten<br>butter</td>, <td>water<br>graham cracker crumbs<br>chopped pecans<br>confectioner's sugar<br>butter<br>coconut flakes<br>frozen orange juice concentrate -- thawed</td>)</tr><tr>List(<td>0.44721359549995787</td>, <td>Toasted ID Bits, Pk</td>, <td>Debbie's Spiced Pecans</td>, <td>shelled peanuts<br>worcestershire sauce<br>butter -- melted<br>bite-size shredded wheat<br>tabasco sauce<br>garlic powder<br>celery salt<br>bite-size oat cereal rings<br>pretzel sticks</td>, <td>worcestershire sauce<br>butter -- melted<br>tabasco sauce<br>pecan halves<br>garlic salt</td>)</tr><tr>List(<td>0.4082482904638631</td>, <td>Curried Pecans</td>, <td>Curried Meat Balls, Pk</td>, <td>pecan halves -- or walnuts<br>melted butter<br>curry powder<br>salt</td>, <td>minced steak<br>dry bread crumbs<br>curry powder<br>egg -- beaten<br>salt<br>few grains pepper</td>)</tr><tr>List(<td>0.3872983346207417</td>, <td>Crunchy Chocolate-Coconut Balls</td>, <td>Cranberry Coconut Fruit Balls</td>, <td>whole wheat flakes -- crisp<br>sweet chocolate squares<br>confectioner's sugar<br>coconut flakes<br>egg -- slightly beaten<br>butter</td>, <td>dried apricots<br>graham cracker crumbs<br>fresh cranberries -- rinsed and drained<br>red food coloring<br>confectioner's sugar<br>coconut flakes<br>pecans<br>grated orange peel -- from 1 orange<br>green food coloring<br>butter</td>)</tr><tr>List(<td>0.3749999999999999</td>, <td>Baked Whole Garlic with French Bread</td>, <td>Rosemary Chicken Wings</td>, <td>black pepper<br>clarified butter<br>garlic -- left whole<br>salt<br>butter -- softened<br>French bread loaf -- sliced and heated<br>cream cheese or soft cheese (optional)<br>olive oil</td>, <td>salt<br>olive oil<br>butter<br>finely chopped shallots<br>black pepper<br>chicken wings<br>dried rosemary<br>lemonade</td>)</tr><tr>List(<td>0.3380617018914066</td>, <td>Sardine Appetizer</td>, <td>Copenhagens</td>, <td>mayonnaise<br>chopped olives<br>toasted bread<br>lemon juice<br>minced pimento<br>stuffed olives<br>mashed sardines</td>, <td>chopped parsley<br>mayonnaise<br>lemon juice<br>waterchestnuts -- canned, drained<br>shrimp</td>)</tr><tr>List(<td>0.3333333333333334</td>, <td>Corn 'n Bacon Sticks, Pk</td>, <td>Pork Meatball With Sweet-Sour Sauce, Pk</td>, <td>-- crumbled<br>margarine or butter -- melted<br>cream-style corn -- canned<br>Bisquick baking mix<br>garlic salt<br>bacon -- crisply fried and</td>, <td>ground pork<br>Bisquick baking mix<br>egg<br>garlic powder<br>sweet-sour sauce -- see recipe<br>garlic salt</td>)</tr><tr>List(<td>0.32732683535398865</td>, <td>Curried Meat Balls, Pk</td>, <td>Antipasti</td>, <td>minced steak<br>dry bread crumbs<br>curry powder<br>egg -- beaten<br>salt<br>few grains pepper</td>, <td>smoked mozzarella cheese -- cut into 3/4 cubes<br>salt<br>julienned fresh basil leaves<br>Italian seasoning<br>julienned sun-dried tomatoes in olive oil -- drained<br>balsamic vinegar -- optional<br>ripe olives<br>mixed greens, such as mesclun, gourmet, It<br>roasted red peppers -- drained<br>egg -- beaten<br>dry bread crumbs<br>dried basil -- optional<br>olive oil<br>artichoke heart quarters -- drained</td>)</tr><tr>List(<td>0.31622776601683794</td>, <td>Cocktail Beer Ball</td>, <td>Sweet and Sour Party Meat Balls</td>, <td>vinegar<br>sugar<br>ground chuck<br>beer<br>catsup<br>worcestershire sauce</td>, <td>worcestershire sauce<br>vinegar<br>hot sauce<br>ground round<br>ground pork<br>pineapple chunks in syrup -- drained<br>sugar<br>finely chopped onion<br>pepper<br>cornstarch<br>soft bread crumbs<br>salt<br>eggs -- beaten<br>green pepper -- diced<br>tomato sauce</td>)</tr><tr>List(<td>0.3162277660168379</td>, <td>Sugar Walnuts</td>, <td>Ella's Divine Date Rum Balls</td>, <td>honey<br>water<br>salt<br>walnuts<br>sugar</td>, <td>dates -- pitted and chopped<br>sugar<br>rice krispies.<br>butter<br>confectioner's sugar -- optional<br>chopped pecans<br>rum<br>salt</td>)</tr><tr>List(<td>0.3162277660168379</td>, <td>Candied Cashews</td>, <td>Ella's Divine Date Rum Balls</td>, <td>cinnamon -- to taste<br>lemon juice<br>sugar<br>cashews -- amount you want<br>butter</td>, <td>dates -- pitted and chopped<br>sugar<br>rice krispies.<br>butter<br>confectioner's sugar -- optional<br>chopped pecans<br>rum<br>salt</td>)</tr><tr>List(<td>0.2981423969999719</td>, <td>Sugar Walnuts</td>, <td>Mexican-Meatball Tidbits</td>, <td>honey<br>water<br>salt<br>walnuts<br>sugar</td>, <td>water<br>egg<br>salt<br>cornmeal -- or fine dry<br>ground beef<br>breadcrumb<br>tomato juice<br>lemon juice<br>Chile mix -- 1 3/4 ounces</td>)</tr><tr>List(<td>0.2981423969999719</td>, <td>Candied Cashews</td>, <td>Mushroom Individuals</td>, <td>cinnamon -- to taste<br>lemon juice<br>sugar<br>cashews -- amount you want<br>butter</td>, <td>sour cream<br>pepper<br>garlic clove -- crushed<br>button mushrooms<br>lemon juice<br>dill weed<br>butter<br>sherry<br>salt</td>)</tr><tr>List(<td>0.294174202707276</td>, <td>Rhode Island Clam Cakes</td>, <td>Swedish Meat Ball Appetizers, Pk</td>, <td>pepper<br>milk<br>salt<br>flour<br>clams, canned with liquid<br>baking powder<br>lard, or more -- for deep frying<br>eggs</td>, <td>sour cream<br>pepper<br>cinnamon<br>milk<br>soft bread crumbs<br>egg<br>ginger<br>cooking oil<br>nutmeg<br>salt<br>ground cloves<br>ground beef<br>brown sugar</td>)</tr><tr>List(<td>0.2886751345948129</td>, <td>Bacon Rollups</td>, <td>Rumaki</td>, <td>bacon<br>thin sandwich bread<br>old English cheese spread</td>, <td>waterchestnuts, canned -- drained<br>soy sauce<br>brown sugar<br>bacon</td>)</tr><tr>List(<td>0.28867513459481287</td>, <td>Potstickers</td>, <td>Mexican-Meatball Tidbits</td>, <td>salt<br>hot chili oil<br>cornstarch<br>green onions -- minced<br>won-ton wrappers -- cut into circles<br>water<br>orange peel -- grated<br>egg<br>ground pork<br>chinese cabbage -- minced<br>peanut oil<br>light soy sauce</td>, <td>water<br>egg<br>salt<br>cornmeal -- or fine dry<br>ground beef<br>breadcrumb<br>tomato juice<br>lemon juice<br>Chile mix -- 1 3/4 ounces</td>)</tr><tr>List(<td>0.282842712474619</td>, <td>Sugar Walnuts</td>, <td>Crispy Pecan Logs, Pk</td>, <td>honey<br>water<br>salt<br>walnuts<br>sugar</td>, <td>vanilla<br>dry milk<br>xxx sugar<br>shortening<br>xxxx sugar<br>oleo<br>flour<br>pecans<br>salt<br>water</td>)</tr><tr>List(<td>0.2773500981126146</td>, <td>Mushroom Individuals</td>, <td>Swedish Meat Ball Appetizers, Pk</td>, <td>sour cream<br>pepper<br>garlic clove -- crushed<br>button mushrooms<br>lemon juice<br>dill weed<br>butter<br>sherry<br>salt</td>, <td>sour cream<br>pepper<br>cinnamon<br>milk<br>soft bread crumbs<br>egg<br>ginger<br>cooking oil<br>nutmeg<br>salt<br>ground cloves<br>ground beef<br>brown sugar</td>)</tr><tr>List(<td>0.2773500981126146</td>, <td>Swedish Meat Ball Appetizers, Pk</td>, <td>Mexican-Meatball Tidbits</td>, <td>sour cream<br>pepper<br>cinnamon<br>milk<br>soft bread crumbs<br>egg<br>ginger<br>cooking oil<br>nutmeg<br>salt<br>ground cloves<br>ground beef<br>brown sugar</td>, <td>water<br>egg<br>salt<br>cornmeal -- or fine dry<br>ground beef<br>breadcrumb<br>tomato juice<br>lemon juice<br>Chile mix -- 1 3/4 ounces</td>)</tr></table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displayTable(\n",
    "    cse.toList.take(20)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting it:\n",
    "\n",
    "Scala/Spark does not offer much plotting options. For convenience, let's embeed a static plotly graph. I'll eventually figure out how to dynamically pass data to the graph from my app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"900\" height=\"800\" frameborder=\"0\" scrolling=\"no\" src=\"https://plot.ly/~rmalarc/3.embed\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "publish.display(\"table\",(\"text/html\" -> (\"\"\"<iframe width=\"900\" height=\"800\" frameborder=\"0\" scrolling=\"no\" src=\"https://plot.ly/~rmalarc/3.embed\"></iframe>\"\"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sc.stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Conclusions\n",
    "\n",
    "* Spark is raw power, not bells and whistles and user friendliness: Here are some of the major limitations/issues I've found\n",
    "  * Lot's of datatypes disparate APIs. For instance, the cosine similarity is buried into a Matrix api, which you can't directly use if you have a plain RDD or SQL dataframe. Lot's of data conversions\n",
    "  * I only found that ONE similarity function (which is the cosine). I didn't get to experiment with other functions.\n",
    "  * I couldn't get it to reference other RDDs within another's functor. For instanace, I had to hardcode the length of the recipe's array as I couldn't directly access it within the second iterator. Due to the same reason, I had to first calculate whatever I wanted to access from within the functor, and bake it into the RDD by using joins. Perhaps this is the Spark way. Lot's of \"Task not serializable\" erros: http://stackoverflow.com/questions/22592811/task-not-serializable-java-io-notserializableexception-when-calling-function-ou\n",
    "* It was really cool to be able to completely parse a plain text list of recipes into a \"dataset\".\n",
    "* The cosine simmilarity seems to work pretty nicely, even in a really sparse scenario such as this one. Better results should be obtained by mastering the list of ingredients."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.10",
   "language": "scala210",
   "name": "scala210"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala210",
   "pygments_lexer": "scala",
   "version": "2.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
